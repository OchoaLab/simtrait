---
title: "`simtrait`: Simulate Complex Traits from Genotypes"
author: "Alejandro Ochoa"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: simtrait.bib
vignette: >
  %\VignetteIndexEntry{simtrait: Simulate Complex Traits from Genotypes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- Weird way to include these definitions for HTML Markdown -->
$\DeclareMathOperator{\E}{E}$
$\DeclareMathOperator{\Cov}{Cov}$


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, cache = FALSE, include = FALSE}
## copied from examples from the "simmer" R package
## after: https://www.enchufa2.es/archives/suggests-and-vignettes.html
## by Iñaki Úcar
required <- c("popkin", "bnpsd") # only suggested since simtrait doesn't need them to run...

if (!all(sapply(required, requireNamespace, quietly = TRUE)))
  knitr::opts_chunk$set(eval = FALSE)
```

# Introduction

This vignette has three main parts.

The first part is a practical example that shows how to use the functions and demonstrates that the random traits generated by this package have the desired covariance structure.

The second part develops the trait model that motivated this package.

The third part explains the algorithm implementation, which follows straightforwardly from the model when ancestral allele frequencies are known.
However, more painful details are necessary when ancestral allele frequencies must be estimated from the genotypes, which induces biases that fortunately can be corrected.

# Sample usage

In this section we first simulated an admixed population using `bnpsd`, then we simulate traits using `simtrait`.
In particular, we simulate a large number of traits to demonstrate that their sample covariance matrix is as expected.

## Load libraries required for this vignette

```{r}
library(popkin)   # to create plots of our covariance matrices
library(bnpsd)    # to simulate an admixed population
library(simtrait) # this package
```

## Simulate an admixed population

```{r}
# dimensions of data/model
# number of loci
m_loci <- 10000
# number of individuals, smaller than usual for easier visualizations
n_ind <- 30
# number of intermediate subpops (source populations for admixed individuals)
k_subpops <- 3

# define population structure
# FST values for 3 subpopulations (proportional/unnormalized)
inbr_subpops <- 1 : k_subpops
bias_coeff <- 0.5 # bias coeff of standard Fst estimator
Fst <- 0.3 # desired final Fst
obj <- admix_prop_1d_linear(
    n_ind = n_ind,
    k_subpops = k_subpops,
    bias_coeff = bias_coeff,
    coanc_subpops = inbr_subpops,
    fst = Fst
)
admix_proportions <- obj$admix_proportions
# rescaled Fst vector for intermediate subpops
inbr_subpops <- obj$coanc_subpops

# get pop structure parameters of the admixed individuals
coancestry <- coanc_admix(admix_proportions, inbr_subpops)
kinship <- coanc_to_kinship(coancestry)

# draw allele freqs and genotypes
out <- draw_all_admix(admix_proportions, inbr_subpops, m_loci)
X <- out$X # genotypes
p_anc <- out$p_anc # ancestral AFs
```

## Simulate a random trait

First we simulate one trait:

```{r}
# parameters of simulation
m_causal <- 100
herit <- 0.8
# default 0, let's try a non-trivial case
mu <- 1
# default 1, also let's see that this more complicated case works well
sigma_sq <- 1.5

# create simulated trait
# case of exact p_anc
obj <- sim_trait(
    X = X,
    m_causal = m_causal,
    herit = herit,
    p_anc = p_anc,
    mu = mu,
    sigma_sq = sigma_sq
)
# trait vector
length(obj$trait)
n_ind
obj$trait
# randomly-picked causal locus index
length( obj$causal_indexes )
m_causal
head( obj$causal_indexes ) # show partially...
# locus effect size vector
length( obj$causal_coeffs )
m_causal
head( obj$causal_coeffs ) # show partially...
```

## Compare sample covariance of trait to theoretical expectation

The interesting validation is simulation a large number of random traits, from which we can estimate a sample covariance matrix to compare to the desired theoretical one.

```{r}
# the theoretical covariance matrix of the trait is calculated by cov_trait
V <- cov_trait(kinship = kinship, herit = herit, sigma_sq = sigma_sq)

# simulate these many traits
n_traits <- 1000
# store in this matrix, initialize with zeroes
Y <- matrix(data = 0, nrow = n_traits, ncol = n_ind)
# start loop
for (i in 1 : n_traits) {
    obj <- sim_trait(
        X = X,
        m_causal = m_causal,
        herit = herit,
        p_anc = p_anc,
        mu = mu,
        sigma_sq = sigma_sq
    )
    Y[i,] <- obj$trait # store in i^th row
}
# estimate sample covariance
V_sample <- cov(Y)
```

First let's verify that the mean is as expected.
Below the red line marks the desired mean.
```{r, fig.width = 3, fig.align = 'center'}
par(mgp = c(2, 0.5, 0))
# reduce margins from default
par(mar = c(3.5, 3, 0, 0) + 0.2)
# visualize distribution
boxplot(rowMeans(Y), xlab = "Simulation", ylab = 'Sample Mean')
# red line marks expected mean
abline(h = mu, col = 'red')
```

Now let's visualize the covariance matrices using `plot_popkin` from the `popkin` package.
Since both matrices have large diagonals, we shrink them somewhat using `inbr_diag` also from the `popkin` package.

```{r, fig.width = 6, fig.height = 2.8, fig.align = 'center'}
# set outer margin for axis labels (left and right are non-zero)
par(oma = c(0, 1.5, 0, 3))
# set inner margin for title (top is non-zero), add padding
par(mar = c(0, 0, 2, 0) + 0.2)
# now plot!
plot_popkin(
    inbr_diag(list(V, V_sample)),
    titles = c('Theoretical', 'Sample Estimate'),
    leg_title = 'Covariance'
)
```

This plot verifies that the empirical covariance matches the theoretical expectation!

## Simulated trait without ancestral allele frequencies

For real data, true ancestral allele frequencies are unknown.
A reasonable trait can still be simulated in these cases, as shown below, but this solution no longer has theoretical guarantees to yield the desired mean value in particular.
The current implementation of `sim_trait` without `p_anc` relies on a known kinship matrix to compensate for having to estimate ancestral allele frequencies and their resulting biases.
In fact, the current `sim_trait` only uses the mean kinship for this adjustment, and the user may simply pass the mean kinship value to obtain the same results.
However, to better agree with `cov_trait`, the algorithm will accept the full kinship matrix and compute the mean internally.
A good kinship matrix estimate can be obtained using the `popkin` package.

For simplicity here we proceed using the true kinship matrix rather than an estimate:
```{r}
# store this in new matrix
Y2 <- matrix(data = 0, nrow = n_traits, ncol = n_ind)
# start loop
for (i in 1 : n_traits) {
    obj <- sim_trait(
        X = X,
        m_causal = m_causal,
        herit = herit,
        kinship = kinship,
        mu = mu,
        sigma_sq = sigma_sq
    )
    Y2[i,] <- obj$trait # store in i^th row
}
# estimate sample covariance
V_sample2 <- cov(Y2)
```
First let's verify the means again.
Recall the red line marks the desired mean.
Below the original sample (simulated using the true `p_anc`) is shown first as "Sample 1", while the new sample based on the kinship matrix is "Sample 2":
```{r, fig.width = 3, fig.align = 'center'}
par(mgp = c(2, 0.5, 0))
# reduce margins from default
par(mar = c(3.5, 3, 0, 0) + 0.2)
# visualize distribution
boxplot(
    list(
        "Sample 1" = rowMeans(Y),
        "Sample 2" = rowMeans(Y2)
    ),
    xlab = "Simulation",
    ylab = 'Sample Mean'
)
# red line marks expected mean
abline(h = mu, col = 'red')
```

Now we compare all three matrices:
```{r, fig.width = 7, fig.height = 2.35, fig.align = 'center'}
# set outer margin for axis labels (left and right are non-zero)
par(oma = c(0, 1.5, 0, 3))
# set inner margin for title (top is non-zero), add padding
par(mar = c(0, 0, 2, 0) + 0.2)
# now plot!
plot_popkin(
    inbr_diag(list(V, V_sample, V_sample2)),
    titles = c('Theoretical', 'Sample Estimate 1', 'Sample Estimate 2'),
    leg_title = 'Covariance'
)
```

This plot shows again good agreement between the sample covariance matrix of traits simulated without true ancestral allele frequencies ("Sample Estimator 2") and the desired "theoretical" covariance matrix.

# Model

Here is a brief summary of the trait model, which explains what this package does internally.

Suppose there are $n$ individuals and $m$ (causal) loci.
For simplicity we shall assume that every locus has an effect size, although in practice many of these coefficients will be zero.
The following variables are part of the model:

| Variable            | Dimensions   | Description                           |
| ------------        | ------------ | -----------                           |
| $\mathbf{X}$        | $n \times m$ | Genotypes                             |
| $\mathbf{x}_i$      | $n \times 1$ | Genotype vector at locus $i$          |
| $\mathbf{y}$        | $n \times 1$ | Trait                                 |
| $\mathbf{\beta}$    | $m \times 1$ | Effect size coefficients              |
| $\mathbf{\epsilon}$ | $n \times 1$ | Non-genetic effects                   |
| $\mathbf{p}$        | $m \times 1$ | Ancestral allele frequencies          |
| $\mathbf{\Phi}$     | $n \times n$ | Kinship matrix                        |
| $\mu_0$             | $1 \times 1$ | Intercept (excludes genetic effects)  |
| $\mu$               | $1 \times 1$ | Trait mean (includes genetic effects) |
| $h^2$               | $1 \times 1$ | Heritability                          |
| $\sigma^2$          | $1 \times 1$ | Trait variance factor                 |
| $\mathbf{1}$        | $n \times 1$ | Vector of ones                        |
| $\mathbf{0}$        | $n \times 1$ | Vector of zeroes                      |
| $\mathbf{I}$        | $n \times n$ | Identity matrix                       |

We assume the linear polygenic model for a quantitative trait:
$$
\mathbf{y} = \mu_0 \mathbf{1} + \mathbf{X} \mathbf{\beta} + \mathbf{\epsilon}.
$$
To analyze the covariance structure of the trait, we shall assume that $\mu_0$ and $\mathbf{\beta}$ are fixed parameters, while $\mathbf{X} = (\mathbf{x}_i)$ and $\mathbf{\epsilon}$ are random with expectations and covariances of
\begin{align*}
	\E[\mathbf{X}] &= 2 \mathbf{1} \mathbf{p}^\intercal
	, \\
	\Cov(\mathbf{x}_i) &= 4 p_i (1-p_i) \mathbf{\Phi}
	, \\
	\E[\mathbf{\epsilon}] &= \mathbf{0}
	, \\
	\Cov(\mathbf{\epsilon}) &= (1-h^2) \sigma^2 \mathbf{I}
	,
\end{align*}
where $\mathbf{p} = (p_i)$.
The expectation of the trait is therefore
\begin{align*}
	\E[\mathbf{y}]
	&= \mu_0 \mathbf{1} + \E[\mathbf{X}] \mathbf{\beta} + \E[\mathbf{\epsilon}]
	\\
	&= \mu_0 \mathbf{1} + 2 \mathbf{1} \mathbf{p}^\intercal \mathbf{\beta}
	,
\end{align*}
which can be written as 
\begin{align*}
	\E[\mathbf{y}]
	= \mu \mathbf{1}
	, \quad \text{where} \quad 
	\mu 
	=
	\mu_0 + 2 \mathbf{p}^\intercal \mathbf{\beta}
	.
\end{align*}
The covariance matrix of the trait is
\begin{align*}
	\Cov(\mathbf{y})
	&=
	\sum_{i=1}^m \Cov(\mathbf{x}_i) \beta_i^2 + \Cov(\mathbf{\epsilon})
	\\
	&=
	\mathbf{\Phi} \sum_{i=1}^m 4 p_i (1-p_i) \beta_i^2 + (1-h^2) \sigma^2 \mathbf{I}
	,
\end{align*}
where $\mathbf{\beta} = (\beta_i)$.
Therefore, we can write the covariance in terms of the heritability and the overall variance scale:
\begin{align*}
	\Cov(\mathbf{y})
	&=
	\sigma^2 \left( 2 h^2 \mathbf{\Phi}  + (1-h^2) \mathbf{I} \right)
	, \quad \text{where}
	\\
	\sigma^2 h^2 
	&= 
	\sum_{i=1}^m 2 p_i (1-p_i) \beta_i^2
	.
\end{align*}
The factor of two in front of $\mathbf{\Phi}$ is traditionally there since for an unstructured population
$2 \mathbf{\Phi} = \mathbf{I}$, in which case the trait covariance simplifies to
$\Cov(\mathbf{y}) = \sigma^2 \mathbf{I}$ for any value of $h^2$.
More broadly, the variance of the trait for any outbred individual is $\sigma^2$ under this parametrization.

# Algorithm

In all cases the user sets the heritability and other parameters but not the effect sizes $\mathbf{\beta}$ directly.
To choose $\mathbf{\beta}$, the algorithm initially draws random coefficients and scales them to yield the desired covariance structure, as follows.

The user provides a genotype matrix and sets the number of causal loci.
The algorithm selects random loci to be the causal ones, by default restricted to loci with sample minor allele frequencies of at least 5\% (the user can change this value).
From this moment on $\mathbf{X}$ will contain only those causal loci.
The initial effect sizes are drawn independently from a standard normal distribution:
$$
\beta_i \sim \text{N}(0,1).
$$
The subsequent adjustments depend on whether the user provides the true ancestral allele frequency vector or the kinship matrix.

Below we divide the algorithm into two steps: (1) scaling the effect sizes, and (2) centering the trait.
Each step forks into two cases: whether the true ancestral allele frequencies are known or not (the latter requires a known kinship matrix).

## Scaling effect sizes 

### Scaling using known ancestral allele frequencies

Here we assume that $\mathbf{p} = (p_i)$ is provided by the user.
The user has also provided the desired values of both $h^2$ and $\sigma^2$.
The initial genetic variance factor is
$$
\sigma^2_0 = \sum_{i=1}^m 2 p_i (1-p_i) \beta_i^2.
$$
We obtain the desired variance by dividing each $\beta_i$ by $\sigma_0$ (which results in a variance of 1) and then multiply by $h \sigma$ (which finally results in the desired variance of $h^2 \sigma^2$).
Combining both steps, the update is
$$
\mathbf{\beta} \leftarrow \mathbf{\beta} \frac{ h \sigma }{\sigma_0}.
$$

### Scaling using a known kinship matrix

When $\mathbf{p}$ isn't known, sample estimates $\mathbf{\hat{p}}$ are constructed from the genotype data.
Let
$$
\hat{p}_i = \frac{1}{2n} \mathbf{1}^\intercal \mathbf{x}_i .
$$
Although this estimator is unbiased ($\E[\mathbf{\hat{p}}] = \mathbf{p}$), the resulting variance estimates of interest become downwardly biased [@Ochoa083923]:
$$
\E \left[ \hat{p}_i \left( 1-\hat{p}_i \right) \right]
= p_i(1-p_i) (1 - \bar{\varphi}),
$$
where $\bar{\varphi} = \frac{1}{n^2} \mathbf{1}^\intercal \mathbf{\Phi} \mathbf{1}$ is the mean kinship coefficient in the data.
Therefore the initial genetic variance factor, estimated as
$$
\hat{\sigma}^2_0 = \sum_{i=1}^m 2 \hat{p}_i (1-\hat{p}_i) \beta_i^2,
$$
has an expectation of
$$
\E \left[ \hat{\sigma}^2_0 \right] = \sigma^2_0 (1 - \bar{\varphi})
$$
Since this additional factor $(1 - \bar{\varphi})$ is known in this setting, the adjusted update
$$
\mathbf{\beta} \leftarrow \mathbf{\beta} \frac{ h \sigma \sqrt{1-\bar{\varphi}} }{\hat{\sigma}_0}
$$
also results in the desired variance.

## Centering the trait

### Centering using known ancestral allele frequencies

This is the prefered approach as it is the only case that guarantees success.
Given our model, we obtain the desired overall trait mean $\mu$ by choosing the intercept to be
$$
\mu_0 
=
\mu - 2 \mathbf{p}^\intercal \mathbf{\beta}
$$

### Centering without ancestral allele frequencies

The solution that this version of the algorithm takes is to choose the intercept
\begin{align*}
	\mu_0 
	&=
	\mu - 2 \hat{\bar{p}} \mathbf{1}_m^\intercal \mathbf{\beta}
	, \quad \text{where} \\
	\hat{\bar{p}}
	&=
	\frac{1}{m} \mathbf{1}_m^\intercal \mathbf{\hat{p}}
	=
	\frac{1}{2mn} \mathbf{1}_m^\intercal \mathbf{X}^\intercal \mathbf{1}_n
	=
	\frac{1}{2} \bar{X}
	,
\end{align*}
where $\mathbf{1}_m$ above are length-$m$ vectors of ones.
This works very well in practice since $\mathbf{\beta}$ is drawn randomly, so it is uncorrelated with the true $\mathbf{p}$.
In this setting it suffices to consider each effect size $\beta_i$ as acting on the average locus, which is treated as having a random ancestral allele frequency $p_i$, and all that matters is the global mean of $p_i$ values.

### How NOT to center the trait vector

Now let's discuss why the obvious way of centering the trait without known ancestral allele frequencies doesn't work.
Why not use the sample allele frequencies as
$$
\mu_0 
=
\mu - 2 \mathbf{\hat{p}}^\intercal \mathbf{\beta} \quad ?
$$
Centering the trait this way is equivalent to centering genotypes at each locus:
$$
\mathbf{y} = \mu \mathbf{1} + \sum_{i=1}^m (\mathbf{x}_i - \hat{p}_i \mathbf{1}) \beta_i + \mathbf{\epsilon}.
$$
However, this operation introduces a distortion in the covariance of the genotypes [@Ochoa083923]: 
$$
\Cov \left( \mathbf{x}_i - \hat{p}_i \mathbf{1} \right)
=
p_i (1-p_i) \left( 
\mathbf{\Phi} 
+ \bar{\varphi} \mathbf{1}\mathbf{1}^\intercal 
- \mathbf{\varphi} \mathbf{1}^\intercal 
- \mathbf{1} \mathbf{\varphi}^\intercal 
\right),
$$
where $\mathbf{\varphi} = \mathbf{\Phi} \mathbf{1}$.
These undesireable distortions propagate to the trait, which we confirmed in simulations (not shown).
It is not clear how these distortions can be corrected for after centering the trait as shown above.

Note that the intercept version we chose instead does not induce this genotype centering, which prevents the undesireable distortions in the trait covariance.

# References
